{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 2,160,512\n",
      "Non-trainable parameters: 23,454,912\n",
      "Total parameters: 25,615,424\n",
      "0.model.conv1.weight: requires_grad = False\n",
      "0.model.bn1.weight: requires_grad = True\n",
      "0.model.bn1.bias: requires_grad = True\n",
      "0.model.layer1.0.conv1.weight: requires_grad = False\n",
      "0.model.layer1.0.bn1.weight: requires_grad = True\n",
      "0.model.layer1.0.bn1.bias: requires_grad = True\n",
      "0.model.layer1.0.conv2.weight: requires_grad = False\n",
      "0.model.layer1.0.bn2.weight: requires_grad = True\n",
      "0.model.layer1.0.bn2.bias: requires_grad = True\n",
      "0.model.layer1.0.conv3.weight: requires_grad = False\n",
      "0.model.layer1.0.bn3.weight: requires_grad = True\n",
      "0.model.layer1.0.bn3.bias: requires_grad = True\n",
      "0.model.layer1.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer1.0.downsample.1.weight: requires_grad = True\n",
      "0.model.layer1.0.downsample.1.bias: requires_grad = True\n",
      "0.model.layer1.1.conv1.weight: requires_grad = False\n",
      "0.model.layer1.1.bn1.weight: requires_grad = True\n",
      "0.model.layer1.1.bn1.bias: requires_grad = True\n",
      "0.model.layer1.1.conv2.weight: requires_grad = False\n",
      "0.model.layer1.1.bn2.weight: requires_grad = True\n",
      "0.model.layer1.1.bn2.bias: requires_grad = True\n",
      "0.model.layer1.1.conv3.weight: requires_grad = False\n",
      "0.model.layer1.1.bn3.weight: requires_grad = True\n",
      "0.model.layer1.1.bn3.bias: requires_grad = True\n",
      "0.model.layer1.2.conv1.weight: requires_grad = False\n",
      "0.model.layer1.2.bn1.weight: requires_grad = True\n",
      "0.model.layer1.2.bn1.bias: requires_grad = True\n",
      "0.model.layer1.2.conv2.weight: requires_grad = False\n",
      "0.model.layer1.2.bn2.weight: requires_grad = True\n",
      "0.model.layer1.2.bn2.bias: requires_grad = True\n",
      "0.model.layer1.2.conv3.weight: requires_grad = False\n",
      "0.model.layer1.2.bn3.weight: requires_grad = True\n",
      "0.model.layer1.2.bn3.bias: requires_grad = True\n",
      "0.model.layer2.0.conv1.weight: requires_grad = False\n",
      "0.model.layer2.0.bn1.weight: requires_grad = True\n",
      "0.model.layer2.0.bn1.bias: requires_grad = True\n",
      "0.model.layer2.0.conv2.weight: requires_grad = False\n",
      "0.model.layer2.0.bn2.weight: requires_grad = True\n",
      "0.model.layer2.0.bn2.bias: requires_grad = True\n",
      "0.model.layer2.0.conv3.weight: requires_grad = False\n",
      "0.model.layer2.0.bn3.weight: requires_grad = True\n",
      "0.model.layer2.0.bn3.bias: requires_grad = True\n",
      "0.model.layer2.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer2.0.downsample.1.weight: requires_grad = True\n",
      "0.model.layer2.0.downsample.1.bias: requires_grad = True\n",
      "0.model.layer2.1.conv1.weight: requires_grad = False\n",
      "0.model.layer2.1.bn1.weight: requires_grad = True\n",
      "0.model.layer2.1.bn1.bias: requires_grad = True\n",
      "0.model.layer2.1.conv2.weight: requires_grad = False\n",
      "0.model.layer2.1.bn2.weight: requires_grad = True\n",
      "0.model.layer2.1.bn2.bias: requires_grad = True\n",
      "0.model.layer2.1.conv3.weight: requires_grad = False\n",
      "0.model.layer2.1.bn3.weight: requires_grad = True\n",
      "0.model.layer2.1.bn3.bias: requires_grad = True\n",
      "0.model.layer2.2.conv1.weight: requires_grad = False\n",
      "0.model.layer2.2.bn1.weight: requires_grad = True\n",
      "0.model.layer2.2.bn1.bias: requires_grad = True\n",
      "0.model.layer2.2.conv2.weight: requires_grad = False\n",
      "0.model.layer2.2.bn2.weight: requires_grad = True\n",
      "0.model.layer2.2.bn2.bias: requires_grad = True\n",
      "0.model.layer2.2.conv3.weight: requires_grad = False\n",
      "0.model.layer2.2.bn3.weight: requires_grad = True\n",
      "0.model.layer2.2.bn3.bias: requires_grad = True\n",
      "0.model.layer2.3.conv1.weight: requires_grad = False\n",
      "0.model.layer2.3.bn1.weight: requires_grad = True\n",
      "0.model.layer2.3.bn1.bias: requires_grad = True\n",
      "0.model.layer2.3.conv2.weight: requires_grad = False\n",
      "0.model.layer2.3.bn2.weight: requires_grad = True\n",
      "0.model.layer2.3.bn2.bias: requires_grad = True\n",
      "0.model.layer2.3.conv3.weight: requires_grad = False\n",
      "0.model.layer2.3.bn3.weight: requires_grad = True\n",
      "0.model.layer2.3.bn3.bias: requires_grad = True\n",
      "0.model.layer3.0.conv1.weight: requires_grad = False\n",
      "0.model.layer3.0.bn1.weight: requires_grad = True\n",
      "0.model.layer3.0.bn1.bias: requires_grad = True\n",
      "0.model.layer3.0.conv2.weight: requires_grad = False\n",
      "0.model.layer3.0.bn2.weight: requires_grad = True\n",
      "0.model.layer3.0.bn2.bias: requires_grad = True\n",
      "0.model.layer3.0.conv3.weight: requires_grad = False\n",
      "0.model.layer3.0.bn3.weight: requires_grad = True\n",
      "0.model.layer3.0.bn3.bias: requires_grad = True\n",
      "0.model.layer3.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer3.0.downsample.1.weight: requires_grad = True\n",
      "0.model.layer3.0.downsample.1.bias: requires_grad = True\n",
      "0.model.layer3.1.conv1.weight: requires_grad = False\n",
      "0.model.layer3.1.bn1.weight: requires_grad = True\n",
      "0.model.layer3.1.bn1.bias: requires_grad = True\n",
      "0.model.layer3.1.conv2.weight: requires_grad = False\n",
      "0.model.layer3.1.bn2.weight: requires_grad = True\n",
      "0.model.layer3.1.bn2.bias: requires_grad = True\n",
      "0.model.layer3.1.conv3.weight: requires_grad = False\n",
      "0.model.layer3.1.bn3.weight: requires_grad = True\n",
      "0.model.layer3.1.bn3.bias: requires_grad = True\n",
      "0.model.layer3.2.conv1.weight: requires_grad = False\n",
      "0.model.layer3.2.bn1.weight: requires_grad = True\n",
      "0.model.layer3.2.bn1.bias: requires_grad = True\n",
      "0.model.layer3.2.conv2.weight: requires_grad = False\n",
      "0.model.layer3.2.bn2.weight: requires_grad = True\n",
      "0.model.layer3.2.bn2.bias: requires_grad = True\n",
      "0.model.layer3.2.conv3.weight: requires_grad = False\n",
      "0.model.layer3.2.bn3.weight: requires_grad = True\n",
      "0.model.layer3.2.bn3.bias: requires_grad = True\n",
      "0.model.layer3.3.conv1.weight: requires_grad = False\n",
      "0.model.layer3.3.bn1.weight: requires_grad = True\n",
      "0.model.layer3.3.bn1.bias: requires_grad = True\n",
      "0.model.layer3.3.conv2.weight: requires_grad = False\n",
      "0.model.layer3.3.bn2.weight: requires_grad = True\n",
      "0.model.layer3.3.bn2.bias: requires_grad = True\n",
      "0.model.layer3.3.conv3.weight: requires_grad = False\n",
      "0.model.layer3.3.bn3.weight: requires_grad = True\n",
      "0.model.layer3.3.bn3.bias: requires_grad = True\n",
      "0.model.layer3.4.conv1.weight: requires_grad = False\n",
      "0.model.layer3.4.bn1.weight: requires_grad = True\n",
      "0.model.layer3.4.bn1.bias: requires_grad = True\n",
      "0.model.layer3.4.conv2.weight: requires_grad = False\n",
      "0.model.layer3.4.bn2.weight: requires_grad = True\n",
      "0.model.layer3.4.bn2.bias: requires_grad = True\n",
      "0.model.layer3.4.conv3.weight: requires_grad = False\n",
      "0.model.layer3.4.bn3.weight: requires_grad = True\n",
      "0.model.layer3.4.bn3.bias: requires_grad = True\n",
      "0.model.layer3.5.conv1.weight: requires_grad = False\n",
      "0.model.layer3.5.bn1.weight: requires_grad = True\n",
      "0.model.layer3.5.bn1.bias: requires_grad = True\n",
      "0.model.layer3.5.conv2.weight: requires_grad = False\n",
      "0.model.layer3.5.bn2.weight: requires_grad = True\n",
      "0.model.layer3.5.bn2.bias: requires_grad = True\n",
      "0.model.layer3.5.conv3.weight: requires_grad = False\n",
      "0.model.layer3.5.bn3.weight: requires_grad = True\n",
      "0.model.layer3.5.bn3.bias: requires_grad = True\n",
      "0.model.layer4.0.conv1.weight: requires_grad = False\n",
      "0.model.layer4.0.bn1.weight: requires_grad = True\n",
      "0.model.layer4.0.bn1.bias: requires_grad = True\n",
      "0.model.layer4.0.conv2.weight: requires_grad = False\n",
      "0.model.layer4.0.bn2.weight: requires_grad = True\n",
      "0.model.layer4.0.bn2.bias: requires_grad = True\n",
      "0.model.layer4.0.conv3.weight: requires_grad = False\n",
      "0.model.layer4.0.bn3.weight: requires_grad = True\n",
      "0.model.layer4.0.bn3.bias: requires_grad = True\n",
      "0.model.layer4.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer4.0.downsample.1.weight: requires_grad = True\n",
      "0.model.layer4.0.downsample.1.bias: requires_grad = True\n",
      "0.model.layer4.1.conv1.weight: requires_grad = False\n",
      "0.model.layer4.1.bn1.weight: requires_grad = True\n",
      "0.model.layer4.1.bn1.bias: requires_grad = True\n",
      "0.model.layer4.1.conv2.weight: requires_grad = False\n",
      "0.model.layer4.1.bn2.weight: requires_grad = True\n",
      "0.model.layer4.1.bn2.bias: requires_grad = True\n",
      "0.model.layer4.1.conv3.weight: requires_grad = False\n",
      "0.model.layer4.1.bn3.weight: requires_grad = True\n",
      "0.model.layer4.1.bn3.bias: requires_grad = True\n",
      "0.model.layer4.2.conv1.weight: requires_grad = False\n",
      "0.model.layer4.2.bn1.weight: requires_grad = True\n",
      "0.model.layer4.2.bn1.bias: requires_grad = True\n",
      "0.model.layer4.2.conv2.weight: requires_grad = False\n",
      "0.model.layer4.2.bn2.weight: requires_grad = True\n",
      "0.model.layer4.2.bn2.bias: requires_grad = True\n",
      "0.model.layer4.2.conv3.weight: requires_grad = False\n",
      "0.model.layer4.2.bn3.weight: requires_grad = True\n",
      "0.model.layer4.2.bn3.bias: requires_grad = True\n",
      "1.2.weight: requires_grad = True\n",
      "1.2.bias: requires_grad = True\n",
      "1.4.weight: requires_grad = True\n",
      "1.6.weight: requires_grad = True\n",
      "1.6.bias: requires_grad = True\n",
      "1.8.weight: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2,\n",
    "    label_func=lambda x: x[0].isupper(), item_tfms=Resize(224))\n",
    "\n",
    "learn = vision_learner(dls, \"resnet50\", metrics=[error_rate, accuracy])\n",
    "\n",
    "def count_parameters(model):\n",
    "    trainable_params = 0\n",
    "    non_trainable_params = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "        else:\n",
    "            non_trainable_params += param.numel()\n",
    "    \n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Non-trainable parameters: {non_trainable_params:,}\")\n",
    "    print(f\"Total parameters: {trainable_params + non_trainable_params:,}\")\n",
    "    \n",
    "    return trainable_params, non_trainable_params\n",
    "\n",
    "count_parameters(learn.model)\n",
    "\n",
    "# learn.unfreeze()\n",
    "\n",
    "for name, param in learn.model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
    "\n",
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.172675</td>\n",
       "      <td>0.072987</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.982409</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.064944</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.993911</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.036647</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.992558</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnth/anaconda3/envs/fastai_ssl/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 3,910,960\n",
      "Non-trainable parameters: 23,508,032\n",
      "Total parameters: 27,418,992\n",
      "0.model.conv1.weight: requires_grad = False\n",
      "0.model.conv1.lora_A: requires_grad = True\n",
      "0.model.conv1.lora_B: requires_grad = True\n",
      "0.model.bn1.weight: requires_grad = False\n",
      "0.model.bn1.bias: requires_grad = False\n",
      "0.model.layer1.0.conv1.weight: requires_grad = False\n",
      "0.model.layer1.0.conv1.lora_A: requires_grad = True\n",
      "0.model.layer1.0.conv1.lora_B: requires_grad = True\n",
      "0.model.layer1.0.bn1.weight: requires_grad = False\n",
      "0.model.layer1.0.bn1.bias: requires_grad = False\n",
      "0.model.layer1.0.conv2.weight: requires_grad = False\n",
      "0.model.layer1.0.conv2.lora_A: requires_grad = True\n",
      "0.model.layer1.0.conv2.lora_B: requires_grad = True\n",
      "0.model.layer1.0.bn2.weight: requires_grad = False\n",
      "0.model.layer1.0.bn2.bias: requires_grad = False\n",
      "0.model.layer1.0.conv3.weight: requires_grad = False\n",
      "0.model.layer1.0.conv3.lora_A: requires_grad = True\n",
      "0.model.layer1.0.conv3.lora_B: requires_grad = True\n",
      "0.model.layer1.0.bn3.weight: requires_grad = False\n",
      "0.model.layer1.0.bn3.bias: requires_grad = False\n",
      "0.model.layer1.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer1.0.downsample.0.lora_A: requires_grad = True\n",
      "0.model.layer1.0.downsample.0.lora_B: requires_grad = True\n",
      "0.model.layer1.0.downsample.1.weight: requires_grad = False\n",
      "0.model.layer1.0.downsample.1.bias: requires_grad = False\n",
      "0.model.layer1.1.conv1.weight: requires_grad = False\n",
      "0.model.layer1.1.conv1.lora_A: requires_grad = True\n",
      "0.model.layer1.1.conv1.lora_B: requires_grad = True\n",
      "0.model.layer1.1.bn1.weight: requires_grad = False\n",
      "0.model.layer1.1.bn1.bias: requires_grad = False\n",
      "0.model.layer1.1.conv2.weight: requires_grad = False\n",
      "0.model.layer1.1.conv2.lora_A: requires_grad = True\n",
      "0.model.layer1.1.conv2.lora_B: requires_grad = True\n",
      "0.model.layer1.1.bn2.weight: requires_grad = False\n",
      "0.model.layer1.1.bn2.bias: requires_grad = False\n",
      "0.model.layer1.1.conv3.weight: requires_grad = False\n",
      "0.model.layer1.1.conv3.lora_A: requires_grad = True\n",
      "0.model.layer1.1.conv3.lora_B: requires_grad = True\n",
      "0.model.layer1.1.bn3.weight: requires_grad = False\n",
      "0.model.layer1.1.bn3.bias: requires_grad = False\n",
      "0.model.layer1.2.conv1.weight: requires_grad = False\n",
      "0.model.layer1.2.conv1.lora_A: requires_grad = True\n",
      "0.model.layer1.2.conv1.lora_B: requires_grad = True\n",
      "0.model.layer1.2.bn1.weight: requires_grad = False\n",
      "0.model.layer1.2.bn1.bias: requires_grad = False\n",
      "0.model.layer1.2.conv2.weight: requires_grad = False\n",
      "0.model.layer1.2.conv2.lora_A: requires_grad = True\n",
      "0.model.layer1.2.conv2.lora_B: requires_grad = True\n",
      "0.model.layer1.2.bn2.weight: requires_grad = False\n",
      "0.model.layer1.2.bn2.bias: requires_grad = False\n",
      "0.model.layer1.2.conv3.weight: requires_grad = False\n",
      "0.model.layer1.2.conv3.lora_A: requires_grad = True\n",
      "0.model.layer1.2.conv3.lora_B: requires_grad = True\n",
      "0.model.layer1.2.bn3.weight: requires_grad = False\n",
      "0.model.layer1.2.bn3.bias: requires_grad = False\n",
      "0.model.layer2.0.conv1.weight: requires_grad = False\n",
      "0.model.layer2.0.conv1.lora_A: requires_grad = True\n",
      "0.model.layer2.0.conv1.lora_B: requires_grad = True\n",
      "0.model.layer2.0.bn1.weight: requires_grad = False\n",
      "0.model.layer2.0.bn1.bias: requires_grad = False\n",
      "0.model.layer2.0.conv2.weight: requires_grad = False\n",
      "0.model.layer2.0.conv2.lora_A: requires_grad = True\n",
      "0.model.layer2.0.conv2.lora_B: requires_grad = True\n",
      "0.model.layer2.0.bn2.weight: requires_grad = False\n",
      "0.model.layer2.0.bn2.bias: requires_grad = False\n",
      "0.model.layer2.0.conv3.weight: requires_grad = False\n",
      "0.model.layer2.0.conv3.lora_A: requires_grad = True\n",
      "0.model.layer2.0.conv3.lora_B: requires_grad = True\n",
      "0.model.layer2.0.bn3.weight: requires_grad = False\n",
      "0.model.layer2.0.bn3.bias: requires_grad = False\n",
      "0.model.layer2.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer2.0.downsample.0.lora_A: requires_grad = True\n",
      "0.model.layer2.0.downsample.0.lora_B: requires_grad = True\n",
      "0.model.layer2.0.downsample.1.weight: requires_grad = False\n",
      "0.model.layer2.0.downsample.1.bias: requires_grad = False\n",
      "0.model.layer2.1.conv1.weight: requires_grad = False\n",
      "0.model.layer2.1.conv1.lora_A: requires_grad = True\n",
      "0.model.layer2.1.conv1.lora_B: requires_grad = True\n",
      "0.model.layer2.1.bn1.weight: requires_grad = False\n",
      "0.model.layer2.1.bn1.bias: requires_grad = False\n",
      "0.model.layer2.1.conv2.weight: requires_grad = False\n",
      "0.model.layer2.1.conv2.lora_A: requires_grad = True\n",
      "0.model.layer2.1.conv2.lora_B: requires_grad = True\n",
      "0.model.layer2.1.bn2.weight: requires_grad = False\n",
      "0.model.layer2.1.bn2.bias: requires_grad = False\n",
      "0.model.layer2.1.conv3.weight: requires_grad = False\n",
      "0.model.layer2.1.conv3.lora_A: requires_grad = True\n",
      "0.model.layer2.1.conv3.lora_B: requires_grad = True\n",
      "0.model.layer2.1.bn3.weight: requires_grad = False\n",
      "0.model.layer2.1.bn3.bias: requires_grad = False\n",
      "0.model.layer2.2.conv1.weight: requires_grad = False\n",
      "0.model.layer2.2.conv1.lora_A: requires_grad = True\n",
      "0.model.layer2.2.conv1.lora_B: requires_grad = True\n",
      "0.model.layer2.2.bn1.weight: requires_grad = False\n",
      "0.model.layer2.2.bn1.bias: requires_grad = False\n",
      "0.model.layer2.2.conv2.weight: requires_grad = False\n",
      "0.model.layer2.2.conv2.lora_A: requires_grad = True\n",
      "0.model.layer2.2.conv2.lora_B: requires_grad = True\n",
      "0.model.layer2.2.bn2.weight: requires_grad = False\n",
      "0.model.layer2.2.bn2.bias: requires_grad = False\n",
      "0.model.layer2.2.conv3.weight: requires_grad = False\n",
      "0.model.layer2.2.conv3.lora_A: requires_grad = True\n",
      "0.model.layer2.2.conv3.lora_B: requires_grad = True\n",
      "0.model.layer2.2.bn3.weight: requires_grad = False\n",
      "0.model.layer2.2.bn3.bias: requires_grad = False\n",
      "0.model.layer2.3.conv1.weight: requires_grad = False\n",
      "0.model.layer2.3.conv1.lora_A: requires_grad = True\n",
      "0.model.layer2.3.conv1.lora_B: requires_grad = True\n",
      "0.model.layer2.3.bn1.weight: requires_grad = False\n",
      "0.model.layer2.3.bn1.bias: requires_grad = False\n",
      "0.model.layer2.3.conv2.weight: requires_grad = False\n",
      "0.model.layer2.3.conv2.lora_A: requires_grad = True\n",
      "0.model.layer2.3.conv2.lora_B: requires_grad = True\n",
      "0.model.layer2.3.bn2.weight: requires_grad = False\n",
      "0.model.layer2.3.bn2.bias: requires_grad = False\n",
      "0.model.layer2.3.conv3.weight: requires_grad = False\n",
      "0.model.layer2.3.conv3.lora_A: requires_grad = True\n",
      "0.model.layer2.3.conv3.lora_B: requires_grad = True\n",
      "0.model.layer2.3.bn3.weight: requires_grad = False\n",
      "0.model.layer2.3.bn3.bias: requires_grad = False\n",
      "0.model.layer3.0.conv1.weight: requires_grad = False\n",
      "0.model.layer3.0.conv1.lora_A: requires_grad = True\n",
      "0.model.layer3.0.conv1.lora_B: requires_grad = True\n",
      "0.model.layer3.0.bn1.weight: requires_grad = False\n",
      "0.model.layer3.0.bn1.bias: requires_grad = False\n",
      "0.model.layer3.0.conv2.weight: requires_grad = False\n",
      "0.model.layer3.0.conv2.lora_A: requires_grad = True\n",
      "0.model.layer3.0.conv2.lora_B: requires_grad = True\n",
      "0.model.layer3.0.bn2.weight: requires_grad = False\n",
      "0.model.layer3.0.bn2.bias: requires_grad = False\n",
      "0.model.layer3.0.conv3.weight: requires_grad = False\n",
      "0.model.layer3.0.conv3.lora_A: requires_grad = True\n",
      "0.model.layer3.0.conv3.lora_B: requires_grad = True\n",
      "0.model.layer3.0.bn3.weight: requires_grad = False\n",
      "0.model.layer3.0.bn3.bias: requires_grad = False\n",
      "0.model.layer3.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer3.0.downsample.0.lora_A: requires_grad = True\n",
      "0.model.layer3.0.downsample.0.lora_B: requires_grad = True\n",
      "0.model.layer3.0.downsample.1.weight: requires_grad = False\n",
      "0.model.layer3.0.downsample.1.bias: requires_grad = False\n",
      "0.model.layer3.1.conv1.weight: requires_grad = False\n",
      "0.model.layer3.1.conv1.lora_A: requires_grad = True\n",
      "0.model.layer3.1.conv1.lora_B: requires_grad = True\n",
      "0.model.layer3.1.bn1.weight: requires_grad = False\n",
      "0.model.layer3.1.bn1.bias: requires_grad = False\n",
      "0.model.layer3.1.conv2.weight: requires_grad = False\n",
      "0.model.layer3.1.conv2.lora_A: requires_grad = True\n",
      "0.model.layer3.1.conv2.lora_B: requires_grad = True\n",
      "0.model.layer3.1.bn2.weight: requires_grad = False\n",
      "0.model.layer3.1.bn2.bias: requires_grad = False\n",
      "0.model.layer3.1.conv3.weight: requires_grad = False\n",
      "0.model.layer3.1.conv3.lora_A: requires_grad = True\n",
      "0.model.layer3.1.conv3.lora_B: requires_grad = True\n",
      "0.model.layer3.1.bn3.weight: requires_grad = False\n",
      "0.model.layer3.1.bn3.bias: requires_grad = False\n",
      "0.model.layer3.2.conv1.weight: requires_grad = False\n",
      "0.model.layer3.2.conv1.lora_A: requires_grad = True\n",
      "0.model.layer3.2.conv1.lora_B: requires_grad = True\n",
      "0.model.layer3.2.bn1.weight: requires_grad = False\n",
      "0.model.layer3.2.bn1.bias: requires_grad = False\n",
      "0.model.layer3.2.conv2.weight: requires_grad = False\n",
      "0.model.layer3.2.conv2.lora_A: requires_grad = True\n",
      "0.model.layer3.2.conv2.lora_B: requires_grad = True\n",
      "0.model.layer3.2.bn2.weight: requires_grad = False\n",
      "0.model.layer3.2.bn2.bias: requires_grad = False\n",
      "0.model.layer3.2.conv3.weight: requires_grad = False\n",
      "0.model.layer3.2.conv3.lora_A: requires_grad = True\n",
      "0.model.layer3.2.conv3.lora_B: requires_grad = True\n",
      "0.model.layer3.2.bn3.weight: requires_grad = False\n",
      "0.model.layer3.2.bn3.bias: requires_grad = False\n",
      "0.model.layer3.3.conv1.weight: requires_grad = False\n",
      "0.model.layer3.3.conv1.lora_A: requires_grad = True\n",
      "0.model.layer3.3.conv1.lora_B: requires_grad = True\n",
      "0.model.layer3.3.bn1.weight: requires_grad = False\n",
      "0.model.layer3.3.bn1.bias: requires_grad = False\n",
      "0.model.layer3.3.conv2.weight: requires_grad = False\n",
      "0.model.layer3.3.conv2.lora_A: requires_grad = True\n",
      "0.model.layer3.3.conv2.lora_B: requires_grad = True\n",
      "0.model.layer3.3.bn2.weight: requires_grad = False\n",
      "0.model.layer3.3.bn2.bias: requires_grad = False\n",
      "0.model.layer3.3.conv3.weight: requires_grad = False\n",
      "0.model.layer3.3.conv3.lora_A: requires_grad = True\n",
      "0.model.layer3.3.conv3.lora_B: requires_grad = True\n",
      "0.model.layer3.3.bn3.weight: requires_grad = False\n",
      "0.model.layer3.3.bn3.bias: requires_grad = False\n",
      "0.model.layer3.4.conv1.weight: requires_grad = False\n",
      "0.model.layer3.4.conv1.lora_A: requires_grad = True\n",
      "0.model.layer3.4.conv1.lora_B: requires_grad = True\n",
      "0.model.layer3.4.bn1.weight: requires_grad = False\n",
      "0.model.layer3.4.bn1.bias: requires_grad = False\n",
      "0.model.layer3.4.conv2.weight: requires_grad = False\n",
      "0.model.layer3.4.conv2.lora_A: requires_grad = True\n",
      "0.model.layer3.4.conv2.lora_B: requires_grad = True\n",
      "0.model.layer3.4.bn2.weight: requires_grad = False\n",
      "0.model.layer3.4.bn2.bias: requires_grad = False\n",
      "0.model.layer3.4.conv3.weight: requires_grad = False\n",
      "0.model.layer3.4.conv3.lora_A: requires_grad = True\n",
      "0.model.layer3.4.conv3.lora_B: requires_grad = True\n",
      "0.model.layer3.4.bn3.weight: requires_grad = False\n",
      "0.model.layer3.4.bn3.bias: requires_grad = False\n",
      "0.model.layer3.5.conv1.weight: requires_grad = False\n",
      "0.model.layer3.5.conv1.lora_A: requires_grad = True\n",
      "0.model.layer3.5.conv1.lora_B: requires_grad = True\n",
      "0.model.layer3.5.bn1.weight: requires_grad = False\n",
      "0.model.layer3.5.bn1.bias: requires_grad = False\n",
      "0.model.layer3.5.conv2.weight: requires_grad = False\n",
      "0.model.layer3.5.conv2.lora_A: requires_grad = True\n",
      "0.model.layer3.5.conv2.lora_B: requires_grad = True\n",
      "0.model.layer3.5.bn2.weight: requires_grad = False\n",
      "0.model.layer3.5.bn2.bias: requires_grad = False\n",
      "0.model.layer3.5.conv3.weight: requires_grad = False\n",
      "0.model.layer3.5.conv3.lora_A: requires_grad = True\n",
      "0.model.layer3.5.conv3.lora_B: requires_grad = True\n",
      "0.model.layer3.5.bn3.weight: requires_grad = False\n",
      "0.model.layer3.5.bn3.bias: requires_grad = False\n",
      "0.model.layer4.0.conv1.weight: requires_grad = False\n",
      "0.model.layer4.0.conv1.lora_A: requires_grad = True\n",
      "0.model.layer4.0.conv1.lora_B: requires_grad = True\n",
      "0.model.layer4.0.bn1.weight: requires_grad = False\n",
      "0.model.layer4.0.bn1.bias: requires_grad = False\n",
      "0.model.layer4.0.conv2.weight: requires_grad = False\n",
      "0.model.layer4.0.conv2.lora_A: requires_grad = True\n",
      "0.model.layer4.0.conv2.lora_B: requires_grad = True\n",
      "0.model.layer4.0.bn2.weight: requires_grad = False\n",
      "0.model.layer4.0.bn2.bias: requires_grad = False\n",
      "0.model.layer4.0.conv3.weight: requires_grad = False\n",
      "0.model.layer4.0.conv3.lora_A: requires_grad = True\n",
      "0.model.layer4.0.conv3.lora_B: requires_grad = True\n",
      "0.model.layer4.0.bn3.weight: requires_grad = False\n",
      "0.model.layer4.0.bn3.bias: requires_grad = False\n",
      "0.model.layer4.0.downsample.0.weight: requires_grad = False\n",
      "0.model.layer4.0.downsample.0.lora_A: requires_grad = True\n",
      "0.model.layer4.0.downsample.0.lora_B: requires_grad = True\n",
      "0.model.layer4.0.downsample.1.weight: requires_grad = False\n",
      "0.model.layer4.0.downsample.1.bias: requires_grad = False\n",
      "0.model.layer4.1.conv1.weight: requires_grad = False\n",
      "0.model.layer4.1.conv1.lora_A: requires_grad = True\n",
      "0.model.layer4.1.conv1.lora_B: requires_grad = True\n",
      "0.model.layer4.1.bn1.weight: requires_grad = False\n",
      "0.model.layer4.1.bn1.bias: requires_grad = False\n",
      "0.model.layer4.1.conv2.weight: requires_grad = False\n",
      "0.model.layer4.1.conv2.lora_A: requires_grad = True\n",
      "0.model.layer4.1.conv2.lora_B: requires_grad = True\n",
      "0.model.layer4.1.bn2.weight: requires_grad = False\n",
      "0.model.layer4.1.bn2.bias: requires_grad = False\n",
      "0.model.layer4.1.conv3.weight: requires_grad = False\n",
      "0.model.layer4.1.conv3.lora_A: requires_grad = True\n",
      "0.model.layer4.1.conv3.lora_B: requires_grad = True\n",
      "0.model.layer4.1.bn3.weight: requires_grad = False\n",
      "0.model.layer4.1.bn3.bias: requires_grad = False\n",
      "0.model.layer4.2.conv1.weight: requires_grad = False\n",
      "0.model.layer4.2.conv1.lora_A: requires_grad = True\n",
      "0.model.layer4.2.conv1.lora_B: requires_grad = True\n",
      "0.model.layer4.2.bn1.weight: requires_grad = False\n",
      "0.model.layer4.2.bn1.bias: requires_grad = False\n",
      "0.model.layer4.2.conv2.weight: requires_grad = False\n",
      "0.model.layer4.2.conv2.lora_A: requires_grad = True\n",
      "0.model.layer4.2.conv2.lora_B: requires_grad = True\n",
      "0.model.layer4.2.bn2.weight: requires_grad = False\n",
      "0.model.layer4.2.bn2.bias: requires_grad = False\n",
      "0.model.layer4.2.conv3.weight: requires_grad = False\n",
      "0.model.layer4.2.conv3.lora_A: requires_grad = True\n",
      "0.model.layer4.2.conv3.lora_B: requires_grad = True\n",
      "0.model.layer4.2.bn3.weight: requires_grad = False\n",
      "0.model.layer4.2.bn3.bias: requires_grad = False\n",
      "1.2.weight: requires_grad = True\n",
      "1.2.bias: requires_grad = True\n",
      "1.4.weight: requires_grad = True\n",
      "1.6.weight: requires_grad = True\n",
      "1.6.bias: requires_grad = True\n",
      "1.8.weight: requires_grad = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Sequential (Input shape: 64 x 3 x 224 x 224)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 112 x 112 \n",
       "LoraConv2d                                61936      False     \n",
       "BatchNorm2d                               128        False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 56 x 56   \n",
       "MaxPool2d                                                      \n",
       "LoraConv2d                                6144       False     \n",
       "BatchNorm2d                               128        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                55296      False     \n",
       "BatchNorm2d                               128        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 56 x 56  \n",
       "LoraConv2d                                21504      False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                21504      False     \n",
       "BatchNorm2d                               512        False     \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 56 x 56   \n",
       "LoraConv2d                                21504      False     \n",
       "BatchNorm2d                               128        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                55296      False     \n",
       "BatchNorm2d                               128        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 56 x 56  \n",
       "LoraConv2d                                21504      False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 64 x 56 x 56   \n",
       "LoraConv2d                                21504      False     \n",
       "BatchNorm2d                               128        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                55296      False     \n",
       "BatchNorm2d                               128        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 56 x 56  \n",
       "LoraConv2d                                21504      False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 56 x 56  \n",
       "LoraConv2d                                38912      False     \n",
       "BatchNorm2d                               256        False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 28 x 28  \n",
       "LoraConv2d                                184320     False     \n",
       "BatchNorm2d                               256        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 28 x 28  \n",
       "LoraConv2d                                75776      False     \n",
       "BatchNorm2d                               1024       False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                143360     False     \n",
       "BatchNorm2d                               1024       False     \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 28 x 28  \n",
       "LoraConv2d                                75776      False     \n",
       "BatchNorm2d                               256        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                184320     False     \n",
       "BatchNorm2d                               256        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 28 x 28  \n",
       "LoraConv2d                                75776      False     \n",
       "BatchNorm2d                               1024       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 28 x 28  \n",
       "LoraConv2d                                75776      False     \n",
       "BatchNorm2d                               256        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                184320     False     \n",
       "BatchNorm2d                               256        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 28 x 28  \n",
       "LoraConv2d                                75776      False     \n",
       "BatchNorm2d                               1024       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 28 x 28  \n",
       "LoraConv2d                                75776      False     \n",
       "BatchNorm2d                               256        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                184320     False     \n",
       "BatchNorm2d                               256        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 28 x 28  \n",
       "LoraConv2d                                75776      False     \n",
       "BatchNorm2d                               1024       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 28 x 28  \n",
       "LoraConv2d                                143360     False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 14 x 14  \n",
       "LoraConv2d                                663552     False     \n",
       "BatchNorm2d                               512        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 14 x 14 \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               2048       False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                548864     False     \n",
       "BatchNorm2d                               2048       False     \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 14 x 14  \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                663552     False     \n",
       "BatchNorm2d                               512        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 14 x 14 \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               2048       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 14 x 14  \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                663552     False     \n",
       "BatchNorm2d                               512        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 14 x 14 \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               2048       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 14 x 14  \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                663552     False     \n",
       "BatchNorm2d                               512        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 14 x 14 \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               2048       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 14 x 14  \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                663552     False     \n",
       "BatchNorm2d                               512        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 14 x 14 \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               2048       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 14 x 14  \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               512        False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                663552     False     \n",
       "BatchNorm2d                               512        False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 1024 x 14 x 14 \n",
       "LoraConv2d                                282624     False     \n",
       "BatchNorm2d                               2048       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 14 x 14  \n",
       "LoraConv2d                                548864     False     \n",
       "BatchNorm2d                               1024       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 7 x 7    \n",
       "LoraConv2d                                2506752    False     \n",
       "BatchNorm2d                               1024       False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 7 x 7   \n",
       "LoraConv2d                                1089536    False     \n",
       "BatchNorm2d                               4096       False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                2146304    False     \n",
       "BatchNorm2d                               4096       False     \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 7 x 7    \n",
       "LoraConv2d                                1089536    False     \n",
       "BatchNorm2d                               1024       False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                2506752    False     \n",
       "BatchNorm2d                               1024       False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 7 x 7   \n",
       "LoraConv2d                                1089536    False     \n",
       "BatchNorm2d                               4096       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 7 x 7    \n",
       "LoraConv2d                                1089536    False     \n",
       "BatchNorm2d                               1024       False     \n",
       "ReLU                                                           \n",
       "LoraConv2d                                2506752    False     \n",
       "BatchNorm2d                               1024       False     \n",
       "Identity                                                       \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 7 x 7   \n",
       "LoraConv2d                                1089536    False     \n",
       "BatchNorm2d                               4096       False     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     64 x 2048 x 1 x 1   \n",
       "AdaptiveAvgPool2d                                              \n",
       "AdaptiveMaxPool2d                                              \n",
       "____________________________________________________________________________\n",
       "                     64 x 4096           \n",
       "Flatten                                                        \n",
       "BatchNorm1d                               8192       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 512            \n",
       "Linear                                    2097152    True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               1024       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 2              \n",
       "Linear                                    1024       True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 27,418,992\n",
       "Total trainable params: 2,107,392\n",
       "Total non-trainable params: 25,311,600\n",
       "\n",
       "Optimizer used: <function Adam at 0x7a82613bba30>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #1\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from lora_adapters import LoraConv2d, apply_adapter, mark_only_lora_as_trainable\n",
    "\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2,\n",
    "    label_func=lambda x: x[0].isupper(), item_tfms=Resize(224))\n",
    "\n",
    "learn = vision_learner(dls, \"resnet50\", metrics=[error_rate, accuracy])\n",
    "# learn.freeze_to(2)\n",
    "\n",
    "learn.model[0].model = apply_adapter(learn.model[0].model, LoraConv2d, rank=16)\n",
    "learn.model[0].model = mark_only_lora_as_trainable(learn.model[0].model)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    trainable_params = 0\n",
    "    non_trainable_params = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "        else:\n",
    "            non_trainable_params += param.numel()\n",
    "    \n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Non-trainable parameters: {non_trainable_params:,}\")\n",
    "    print(f\"Total parameters: {trainable_params + non_trainable_params:,}\")\n",
    "    \n",
    "    return trainable_params, non_trainable_params\n",
    "\n",
    "count_parameters(learn.model)\n",
    "\n",
    "for name, param in learn.model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.195193</td>\n",
       "      <td>0.120581</td>\n",
       "      <td>0.015562</td>\n",
       "      <td>0.984438</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.081211</td>\n",
       "      <td>0.031215</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.991881</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.996617</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([64, 3, 7, 7])\n",
      "---\n",
      "Layer: conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([112, 21])\n",
      "---\n",
      "Layer: conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([448, 112])\n",
      "---\n",
      "Layer: bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.0.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([64, 64, 1, 1])\n",
      "---\n",
      "Layer: layer1.0.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 64])\n",
      "---\n",
      "Layer: layer1.0.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64, 16])\n",
      "---\n",
      "Layer: layer1.0.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.0.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.0.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([64, 64, 3, 3])\n",
      "---\n",
      "Layer: layer1.0.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 192])\n",
      "---\n",
      "Layer: layer1.0.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([192, 48])\n",
      "---\n",
      "Layer: layer1.0.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.0.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.0.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 64, 1, 1])\n",
      "---\n",
      "Layer: layer1.0.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 64])\n",
      "---\n",
      "Layer: layer1.0.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer1.0.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer1.0.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer1.0.downsample.0.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 64, 1, 1])\n",
      "---\n",
      "Layer: layer1.0.downsample.0.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 64])\n",
      "---\n",
      "Layer: layer1.0.downsample.0.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer1.0.downsample.1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer1.0.downsample.1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer1.1.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([64, 256, 1, 1])\n",
      "---\n",
      "Layer: layer1.1.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer1.1.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64, 16])\n",
      "---\n",
      "Layer: layer1.1.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.1.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.1.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([64, 64, 3, 3])\n",
      "---\n",
      "Layer: layer1.1.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 192])\n",
      "---\n",
      "Layer: layer1.1.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([192, 48])\n",
      "---\n",
      "Layer: layer1.1.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.1.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.1.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 64, 1, 1])\n",
      "---\n",
      "Layer: layer1.1.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 64])\n",
      "---\n",
      "Layer: layer1.1.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer1.1.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer1.1.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer1.2.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([64, 256, 1, 1])\n",
      "---\n",
      "Layer: layer1.2.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer1.2.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64, 16])\n",
      "---\n",
      "Layer: layer1.2.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.2.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.2.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([64, 64, 3, 3])\n",
      "---\n",
      "Layer: layer1.2.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 192])\n",
      "---\n",
      "Layer: layer1.2.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([192, 48])\n",
      "---\n",
      "Layer: layer1.2.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.2.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([64])\n",
      "---\n",
      "Layer: layer1.2.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 64, 1, 1])\n",
      "---\n",
      "Layer: layer1.2.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 64])\n",
      "---\n",
      "Layer: layer1.2.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer1.2.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer1.2.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer2.0.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 256, 1, 1])\n",
      "---\n",
      "Layer: layer2.0.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer2.0.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128, 16])\n",
      "---\n",
      "Layer: layer2.0.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.0.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.0.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 128, 3, 3])\n",
      "---\n",
      "Layer: layer2.0.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 384])\n",
      "---\n",
      "Layer: layer2.0.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([384, 48])\n",
      "---\n",
      "Layer: layer2.0.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.0.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.0.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 128, 1, 1])\n",
      "---\n",
      "Layer: layer2.0.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 128])\n",
      "---\n",
      "Layer: layer2.0.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer2.0.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.0.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.0.downsample.0.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 256, 1, 1])\n",
      "---\n",
      "Layer: layer2.0.downsample.0.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer2.0.downsample.0.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer2.0.downsample.1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.0.downsample.1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.1.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 512, 1, 1])\n",
      "---\n",
      "Layer: layer2.1.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer2.1.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128, 16])\n",
      "---\n",
      "Layer: layer2.1.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.1.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.1.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 128, 3, 3])\n",
      "---\n",
      "Layer: layer2.1.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 384])\n",
      "---\n",
      "Layer: layer2.1.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([384, 48])\n",
      "---\n",
      "Layer: layer2.1.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.1.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.1.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 128, 1, 1])\n",
      "---\n",
      "Layer: layer2.1.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 128])\n",
      "---\n",
      "Layer: layer2.1.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer2.1.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.1.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.2.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 512, 1, 1])\n",
      "---\n",
      "Layer: layer2.2.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer2.2.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128, 16])\n",
      "---\n",
      "Layer: layer2.2.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.2.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.2.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 128, 3, 3])\n",
      "---\n",
      "Layer: layer2.2.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 384])\n",
      "---\n",
      "Layer: layer2.2.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([384, 48])\n",
      "---\n",
      "Layer: layer2.2.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.2.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.2.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 128, 1, 1])\n",
      "---\n",
      "Layer: layer2.2.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 128])\n",
      "---\n",
      "Layer: layer2.2.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer2.2.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.2.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.3.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 512, 1, 1])\n",
      "---\n",
      "Layer: layer2.3.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer2.3.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128, 16])\n",
      "---\n",
      "Layer: layer2.3.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.3.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.3.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([128, 128, 3, 3])\n",
      "---\n",
      "Layer: layer2.3.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 384])\n",
      "---\n",
      "Layer: layer2.3.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([384, 48])\n",
      "---\n",
      "Layer: layer2.3.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.3.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([128])\n",
      "---\n",
      "Layer: layer2.3.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 128, 1, 1])\n",
      "---\n",
      "Layer: layer2.3.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 128])\n",
      "---\n",
      "Layer: layer2.3.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer2.3.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer2.3.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer3.0.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 512, 1, 1])\n",
      "---\n",
      "Layer: layer3.0.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer3.0.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer3.0.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.0.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.0.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 256, 3, 3])\n",
      "---\n",
      "Layer: layer3.0.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 768])\n",
      "---\n",
      "Layer: layer3.0.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([768, 48])\n",
      "---\n",
      "Layer: layer3.0.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.0.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.0.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([1024, 256, 1, 1])\n",
      "---\n",
      "Layer: layer3.0.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer3.0.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024, 16])\n",
      "---\n",
      "Layer: layer3.0.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.0.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.0.downsample.0.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([1024, 512, 1, 1])\n",
      "---\n",
      "Layer: layer3.0.downsample.0.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer3.0.downsample.0.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024, 16])\n",
      "---\n",
      "Layer: layer3.0.downsample.1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.0.downsample.1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.1.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 1024, 1, 1])\n",
      "---\n",
      "Layer: layer3.1.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 1024])\n",
      "---\n",
      "Layer: layer3.1.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer3.1.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.1.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.1.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 256, 3, 3])\n",
      "---\n",
      "Layer: layer3.1.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 768])\n",
      "---\n",
      "Layer: layer3.1.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([768, 48])\n",
      "---\n",
      "Layer: layer3.1.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.1.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.1.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([1024, 256, 1, 1])\n",
      "---\n",
      "Layer: layer3.1.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer3.1.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024, 16])\n",
      "---\n",
      "Layer: layer3.1.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.1.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.2.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 1024, 1, 1])\n",
      "---\n",
      "Layer: layer3.2.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 1024])\n",
      "---\n",
      "Layer: layer3.2.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer3.2.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.2.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.2.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 256, 3, 3])\n",
      "---\n",
      "Layer: layer3.2.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 768])\n",
      "---\n",
      "Layer: layer3.2.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([768, 48])\n",
      "---\n",
      "Layer: layer3.2.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.2.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.2.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([1024, 256, 1, 1])\n",
      "---\n",
      "Layer: layer3.2.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer3.2.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024, 16])\n",
      "---\n",
      "Layer: layer3.2.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.2.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.3.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 1024, 1, 1])\n",
      "---\n",
      "Layer: layer3.3.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 1024])\n",
      "---\n",
      "Layer: layer3.3.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer3.3.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.3.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.3.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 256, 3, 3])\n",
      "---\n",
      "Layer: layer3.3.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 768])\n",
      "---\n",
      "Layer: layer3.3.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([768, 48])\n",
      "---\n",
      "Layer: layer3.3.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.3.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.3.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([1024, 256, 1, 1])\n",
      "---\n",
      "Layer: layer3.3.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer3.3.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024, 16])\n",
      "---\n",
      "Layer: layer3.3.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.3.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.4.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 1024, 1, 1])\n",
      "---\n",
      "Layer: layer3.4.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 1024])\n",
      "---\n",
      "Layer: layer3.4.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer3.4.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.4.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.4.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 256, 3, 3])\n",
      "---\n",
      "Layer: layer3.4.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 768])\n",
      "---\n",
      "Layer: layer3.4.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([768, 48])\n",
      "---\n",
      "Layer: layer3.4.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.4.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.4.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([1024, 256, 1, 1])\n",
      "---\n",
      "Layer: layer3.4.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer3.4.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024, 16])\n",
      "---\n",
      "Layer: layer3.4.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.4.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.5.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 1024, 1, 1])\n",
      "---\n",
      "Layer: layer3.5.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 1024])\n",
      "---\n",
      "Layer: layer3.5.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256, 16])\n",
      "---\n",
      "Layer: layer3.5.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.5.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.5.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([256, 256, 3, 3])\n",
      "---\n",
      "Layer: layer3.5.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 768])\n",
      "---\n",
      "Layer: layer3.5.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([768, 48])\n",
      "---\n",
      "Layer: layer3.5.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.5.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([256])\n",
      "---\n",
      "Layer: layer3.5.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([1024, 256, 1, 1])\n",
      "---\n",
      "Layer: layer3.5.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 256])\n",
      "---\n",
      "Layer: layer3.5.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024, 16])\n",
      "---\n",
      "Layer: layer3.5.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer3.5.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1024])\n",
      "---\n",
      "Layer: layer4.0.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 1024, 1, 1])\n",
      "---\n",
      "Layer: layer4.0.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 1024])\n",
      "---\n",
      "Layer: layer4.0.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer4.0.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.0.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.0.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 512, 3, 3])\n",
      "---\n",
      "Layer: layer4.0.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 1536])\n",
      "---\n",
      "Layer: layer4.0.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1536, 48])\n",
      "---\n",
      "Layer: layer4.0.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.0.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.0.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([2048, 512, 1, 1])\n",
      "---\n",
      "Layer: layer4.0.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer4.0.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048, 16])\n",
      "---\n",
      "Layer: layer4.0.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: layer4.0.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: layer4.0.downsample.0.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([2048, 1024, 1, 1])\n",
      "---\n",
      "Layer: layer4.0.downsample.0.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 1024])\n",
      "---\n",
      "Layer: layer4.0.downsample.0.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048, 16])\n",
      "---\n",
      "Layer: layer4.0.downsample.1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: layer4.0.downsample.1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: layer4.1.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 2048, 1, 1])\n",
      "---\n",
      "Layer: layer4.1.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 2048])\n",
      "---\n",
      "Layer: layer4.1.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer4.1.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.1.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.1.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 512, 3, 3])\n",
      "---\n",
      "Layer: layer4.1.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 1536])\n",
      "---\n",
      "Layer: layer4.1.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1536, 48])\n",
      "---\n",
      "Layer: layer4.1.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.1.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.1.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([2048, 512, 1, 1])\n",
      "---\n",
      "Layer: layer4.1.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer4.1.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048, 16])\n",
      "---\n",
      "Layer: layer4.1.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: layer4.1.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: layer4.2.conv1.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 2048, 1, 1])\n",
      "---\n",
      "Layer: layer4.2.conv1.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 2048])\n",
      "---\n",
      "Layer: layer4.2.conv1.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512, 16])\n",
      "---\n",
      "Layer: layer4.2.bn1.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.2.bn1.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.2.conv2.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([512, 512, 3, 3])\n",
      "---\n",
      "Layer: layer4.2.conv2.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([48, 1536])\n",
      "---\n",
      "Layer: layer4.2.conv2.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1536, 48])\n",
      "---\n",
      "Layer: layer4.2.bn2.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.2.bn2.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([512])\n",
      "---\n",
      "Layer: layer4.2.conv3.weight\n",
      "  Trainable: False\n",
      "  Shape: torch.Size([2048, 512, 1, 1])\n",
      "---\n",
      "Layer: layer4.2.conv3.lora_A\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([16, 512])\n",
      "---\n",
      "Layer: layer4.2.conv3.lora_B\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048, 16])\n",
      "---\n",
      "Layer: layer4.2.bn3.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: layer4.2.bn3.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([2048])\n",
      "---\n",
      "Layer: fc.weight\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1000, 2048])\n",
      "---\n",
      "Layer: fc.bias\n",
      "  Trainable: True\n",
      "  Shape: torch.Size([1000])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model('resnet50', pretrained=True).to(device)\n",
    "apply_adapter(model, LoraConv2d, rank=16)\n",
    "\n",
    "trainable_layers = []\n",
    "for name, param in model.named_parameters():\n",
    "\n",
    "    trainable_layers.append((name, param.numel(), param.requires_grad))\n",
    "\n",
    "    print(f\"Layer: {name}\")\n",
    "    print(f\"  Trainable: {param.requires_grad}\")\n",
    "    print(f\"  Shape: {param.shape}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1.weight', 9408, False),\n",
       " ('conv1.lora_A', 2352, True),\n",
       " ('conv1.lora_B', 50176, True),\n",
       " ('bn1.weight', 64, True),\n",
       " ('bn1.bias', 64, True),\n",
       " ('layer1.0.conv1.weight', 4096, False),\n",
       " ('layer1.0.conv1.lora_A', 1024, True),\n",
       " ('layer1.0.conv1.lora_B', 1024, True),\n",
       " ('layer1.0.bn1.weight', 64, True),\n",
       " ('layer1.0.bn1.bias', 64, True),\n",
       " ('layer1.0.conv2.weight', 36864, False),\n",
       " ('layer1.0.conv2.lora_A', 9216, True),\n",
       " ('layer1.0.conv2.lora_B', 9216, True),\n",
       " ('layer1.0.bn2.weight', 64, True),\n",
       " ('layer1.0.bn2.bias', 64, True),\n",
       " ('layer1.0.conv3.weight', 16384, False),\n",
       " ('layer1.0.conv3.lora_A', 1024, True),\n",
       " ('layer1.0.conv3.lora_B', 4096, True),\n",
       " ('layer1.0.bn3.weight', 256, True),\n",
       " ('layer1.0.bn3.bias', 256, True),\n",
       " ('layer1.0.downsample.0.weight', 16384, False),\n",
       " ('layer1.0.downsample.0.lora_A', 1024, True),\n",
       " ('layer1.0.downsample.0.lora_B', 4096, True),\n",
       " ('layer1.0.downsample.1.weight', 256, True),\n",
       " ('layer1.0.downsample.1.bias', 256, True),\n",
       " ('layer1.1.conv1.weight', 16384, False),\n",
       " ('layer1.1.conv1.lora_A', 4096, True),\n",
       " ('layer1.1.conv1.lora_B', 1024, True),\n",
       " ('layer1.1.bn1.weight', 64, True),\n",
       " ('layer1.1.bn1.bias', 64, True),\n",
       " ('layer1.1.conv2.weight', 36864, False),\n",
       " ('layer1.1.conv2.lora_A', 9216, True),\n",
       " ('layer1.1.conv2.lora_B', 9216, True),\n",
       " ('layer1.1.bn2.weight', 64, True),\n",
       " ('layer1.1.bn2.bias', 64, True),\n",
       " ('layer1.1.conv3.weight', 16384, False),\n",
       " ('layer1.1.conv3.lora_A', 1024, True),\n",
       " ('layer1.1.conv3.lora_B', 4096, True),\n",
       " ('layer1.1.bn3.weight', 256, True),\n",
       " ('layer1.1.bn3.bias', 256, True),\n",
       " ('layer1.2.conv1.weight', 16384, False),\n",
       " ('layer1.2.conv1.lora_A', 4096, True),\n",
       " ('layer1.2.conv1.lora_B', 1024, True),\n",
       " ('layer1.2.bn1.weight', 64, True),\n",
       " ('layer1.2.bn1.bias', 64, True),\n",
       " ('layer1.2.conv2.weight', 36864, False),\n",
       " ('layer1.2.conv2.lora_A', 9216, True),\n",
       " ('layer1.2.conv2.lora_B', 9216, True),\n",
       " ('layer1.2.bn2.weight', 64, True),\n",
       " ('layer1.2.bn2.bias', 64, True),\n",
       " ('layer1.2.conv3.weight', 16384, False),\n",
       " ('layer1.2.conv3.lora_A', 1024, True),\n",
       " ('layer1.2.conv3.lora_B', 4096, True),\n",
       " ('layer1.2.bn3.weight', 256, True),\n",
       " ('layer1.2.bn3.bias', 256, True),\n",
       " ('layer2.0.conv1.weight', 32768, False),\n",
       " ('layer2.0.conv1.lora_A', 4096, True),\n",
       " ('layer2.0.conv1.lora_B', 2048, True),\n",
       " ('layer2.0.bn1.weight', 128, True),\n",
       " ('layer2.0.bn1.bias', 128, True),\n",
       " ('layer2.0.conv2.weight', 147456, False),\n",
       " ('layer2.0.conv2.lora_A', 18432, True),\n",
       " ('layer2.0.conv2.lora_B', 18432, True),\n",
       " ('layer2.0.bn2.weight', 128, True),\n",
       " ('layer2.0.bn2.bias', 128, True),\n",
       " ('layer2.0.conv3.weight', 65536, False),\n",
       " ('layer2.0.conv3.lora_A', 2048, True),\n",
       " ('layer2.0.conv3.lora_B', 8192, True),\n",
       " ('layer2.0.bn3.weight', 512, True),\n",
       " ('layer2.0.bn3.bias', 512, True),\n",
       " ('layer2.0.downsample.0.weight', 131072, False),\n",
       " ('layer2.0.downsample.0.lora_A', 4096, True),\n",
       " ('layer2.0.downsample.0.lora_B', 8192, True),\n",
       " ('layer2.0.downsample.1.weight', 512, True),\n",
       " ('layer2.0.downsample.1.bias', 512, True),\n",
       " ('layer2.1.conv1.weight', 65536, False),\n",
       " ('layer2.1.conv1.lora_A', 8192, True),\n",
       " ('layer2.1.conv1.lora_B', 2048, True),\n",
       " ('layer2.1.bn1.weight', 128, True),\n",
       " ('layer2.1.bn1.bias', 128, True),\n",
       " ('layer2.1.conv2.weight', 147456, False),\n",
       " ('layer2.1.conv2.lora_A', 18432, True),\n",
       " ('layer2.1.conv2.lora_B', 18432, True),\n",
       " ('layer2.1.bn2.weight', 128, True),\n",
       " ('layer2.1.bn2.bias', 128, True),\n",
       " ('layer2.1.conv3.weight', 65536, False),\n",
       " ('layer2.1.conv3.lora_A', 2048, True),\n",
       " ('layer2.1.conv3.lora_B', 8192, True),\n",
       " ('layer2.1.bn3.weight', 512, True),\n",
       " ('layer2.1.bn3.bias', 512, True),\n",
       " ('layer2.2.conv1.weight', 65536, False),\n",
       " ('layer2.2.conv1.lora_A', 8192, True),\n",
       " ('layer2.2.conv1.lora_B', 2048, True),\n",
       " ('layer2.2.bn1.weight', 128, True),\n",
       " ('layer2.2.bn1.bias', 128, True),\n",
       " ('layer2.2.conv2.weight', 147456, False),\n",
       " ('layer2.2.conv2.lora_A', 18432, True),\n",
       " ('layer2.2.conv2.lora_B', 18432, True),\n",
       " ('layer2.2.bn2.weight', 128, True),\n",
       " ('layer2.2.bn2.bias', 128, True),\n",
       " ('layer2.2.conv3.weight', 65536, False),\n",
       " ('layer2.2.conv3.lora_A', 2048, True),\n",
       " ('layer2.2.conv3.lora_B', 8192, True),\n",
       " ('layer2.2.bn3.weight', 512, True),\n",
       " ('layer2.2.bn3.bias', 512, True),\n",
       " ('layer2.3.conv1.weight', 65536, False),\n",
       " ('layer2.3.conv1.lora_A', 8192, True),\n",
       " ('layer2.3.conv1.lora_B', 2048, True),\n",
       " ('layer2.3.bn1.weight', 128, True),\n",
       " ('layer2.3.bn1.bias', 128, True),\n",
       " ('layer2.3.conv2.weight', 147456, False),\n",
       " ('layer2.3.conv2.lora_A', 18432, True),\n",
       " ('layer2.3.conv2.lora_B', 18432, True),\n",
       " ('layer2.3.bn2.weight', 128, True),\n",
       " ('layer2.3.bn2.bias', 128, True),\n",
       " ('layer2.3.conv3.weight', 65536, False),\n",
       " ('layer2.3.conv3.lora_A', 2048, True),\n",
       " ('layer2.3.conv3.lora_B', 8192, True),\n",
       " ('layer2.3.bn3.weight', 512, True),\n",
       " ('layer2.3.bn3.bias', 512, True),\n",
       " ('layer3.0.conv1.weight', 131072, False),\n",
       " ('layer3.0.conv1.lora_A', 8192, True),\n",
       " ('layer3.0.conv1.lora_B', 4096, True),\n",
       " ('layer3.0.bn1.weight', 256, True),\n",
       " ('layer3.0.bn1.bias', 256, True),\n",
       " ('layer3.0.conv2.weight', 589824, False),\n",
       " ('layer3.0.conv2.lora_A', 36864, True),\n",
       " ('layer3.0.conv2.lora_B', 36864, True),\n",
       " ('layer3.0.bn2.weight', 256, True),\n",
       " ('layer3.0.bn2.bias', 256, True),\n",
       " ('layer3.0.conv3.weight', 262144, False),\n",
       " ('layer3.0.conv3.lora_A', 4096, True),\n",
       " ('layer3.0.conv3.lora_B', 16384, True),\n",
       " ('layer3.0.bn3.weight', 1024, True),\n",
       " ('layer3.0.bn3.bias', 1024, True),\n",
       " ('layer3.0.downsample.0.weight', 524288, False),\n",
       " ('layer3.0.downsample.0.lora_A', 8192, True),\n",
       " ('layer3.0.downsample.0.lora_B', 16384, True),\n",
       " ('layer3.0.downsample.1.weight', 1024, True),\n",
       " ('layer3.0.downsample.1.bias', 1024, True),\n",
       " ('layer3.1.conv1.weight', 262144, False),\n",
       " ('layer3.1.conv1.lora_A', 16384, True),\n",
       " ('layer3.1.conv1.lora_B', 4096, True),\n",
       " ('layer3.1.bn1.weight', 256, True),\n",
       " ('layer3.1.bn1.bias', 256, True),\n",
       " ('layer3.1.conv2.weight', 589824, False),\n",
       " ('layer3.1.conv2.lora_A', 36864, True),\n",
       " ('layer3.1.conv2.lora_B', 36864, True),\n",
       " ('layer3.1.bn2.weight', 256, True),\n",
       " ('layer3.1.bn2.bias', 256, True),\n",
       " ('layer3.1.conv3.weight', 262144, False),\n",
       " ('layer3.1.conv3.lora_A', 4096, True),\n",
       " ('layer3.1.conv3.lora_B', 16384, True),\n",
       " ('layer3.1.bn3.weight', 1024, True),\n",
       " ('layer3.1.bn3.bias', 1024, True),\n",
       " ('layer3.2.conv1.weight', 262144, False),\n",
       " ('layer3.2.conv1.lora_A', 16384, True),\n",
       " ('layer3.2.conv1.lora_B', 4096, True),\n",
       " ('layer3.2.bn1.weight', 256, True),\n",
       " ('layer3.2.bn1.bias', 256, True),\n",
       " ('layer3.2.conv2.weight', 589824, False),\n",
       " ('layer3.2.conv2.lora_A', 36864, True),\n",
       " ('layer3.2.conv2.lora_B', 36864, True),\n",
       " ('layer3.2.bn2.weight', 256, True),\n",
       " ('layer3.2.bn2.bias', 256, True),\n",
       " ('layer3.2.conv3.weight', 262144, False),\n",
       " ('layer3.2.conv3.lora_A', 4096, True),\n",
       " ('layer3.2.conv3.lora_B', 16384, True),\n",
       " ('layer3.2.bn3.weight', 1024, True),\n",
       " ('layer3.2.bn3.bias', 1024, True),\n",
       " ('layer3.3.conv1.weight', 262144, False),\n",
       " ('layer3.3.conv1.lora_A', 16384, True),\n",
       " ('layer3.3.conv1.lora_B', 4096, True),\n",
       " ('layer3.3.bn1.weight', 256, True),\n",
       " ('layer3.3.bn1.bias', 256, True),\n",
       " ('layer3.3.conv2.weight', 589824, False),\n",
       " ('layer3.3.conv2.lora_A', 36864, True),\n",
       " ('layer3.3.conv2.lora_B', 36864, True),\n",
       " ('layer3.3.bn2.weight', 256, True),\n",
       " ('layer3.3.bn2.bias', 256, True),\n",
       " ('layer3.3.conv3.weight', 262144, False),\n",
       " ('layer3.3.conv3.lora_A', 4096, True),\n",
       " ('layer3.3.conv3.lora_B', 16384, True),\n",
       " ('layer3.3.bn3.weight', 1024, True),\n",
       " ('layer3.3.bn3.bias', 1024, True),\n",
       " ('layer3.4.conv1.weight', 262144, False),\n",
       " ('layer3.4.conv1.lora_A', 16384, True),\n",
       " ('layer3.4.conv1.lora_B', 4096, True),\n",
       " ('layer3.4.bn1.weight', 256, True),\n",
       " ('layer3.4.bn1.bias', 256, True),\n",
       " ('layer3.4.conv2.weight', 589824, False),\n",
       " ('layer3.4.conv2.lora_A', 36864, True),\n",
       " ('layer3.4.conv2.lora_B', 36864, True),\n",
       " ('layer3.4.bn2.weight', 256, True),\n",
       " ('layer3.4.bn2.bias', 256, True),\n",
       " ('layer3.4.conv3.weight', 262144, False),\n",
       " ('layer3.4.conv3.lora_A', 4096, True),\n",
       " ('layer3.4.conv3.lora_B', 16384, True),\n",
       " ('layer3.4.bn3.weight', 1024, True),\n",
       " ('layer3.4.bn3.bias', 1024, True),\n",
       " ('layer3.5.conv1.weight', 262144, False),\n",
       " ('layer3.5.conv1.lora_A', 16384, True),\n",
       " ('layer3.5.conv1.lora_B', 4096, True),\n",
       " ('layer3.5.bn1.weight', 256, True),\n",
       " ('layer3.5.bn1.bias', 256, True),\n",
       " ('layer3.5.conv2.weight', 589824, False),\n",
       " ('layer3.5.conv2.lora_A', 36864, True),\n",
       " ('layer3.5.conv2.lora_B', 36864, True),\n",
       " ('layer3.5.bn2.weight', 256, True),\n",
       " ('layer3.5.bn2.bias', 256, True),\n",
       " ('layer3.5.conv3.weight', 262144, False),\n",
       " ('layer3.5.conv3.lora_A', 4096, True),\n",
       " ('layer3.5.conv3.lora_B', 16384, True),\n",
       " ('layer3.5.bn3.weight', 1024, True),\n",
       " ('layer3.5.bn3.bias', 1024, True),\n",
       " ('layer4.0.conv1.weight', 524288, False),\n",
       " ('layer4.0.conv1.lora_A', 16384, True),\n",
       " ('layer4.0.conv1.lora_B', 8192, True),\n",
       " ('layer4.0.bn1.weight', 512, True),\n",
       " ('layer4.0.bn1.bias', 512, True),\n",
       " ('layer4.0.conv2.weight', 2359296, False),\n",
       " ('layer4.0.conv2.lora_A', 73728, True),\n",
       " ('layer4.0.conv2.lora_B', 73728, True),\n",
       " ('layer4.0.bn2.weight', 512, True),\n",
       " ('layer4.0.bn2.bias', 512, True),\n",
       " ('layer4.0.conv3.weight', 1048576, False),\n",
       " ('layer4.0.conv3.lora_A', 8192, True),\n",
       " ('layer4.0.conv3.lora_B', 32768, True),\n",
       " ('layer4.0.bn3.weight', 2048, True),\n",
       " ('layer4.0.bn3.bias', 2048, True),\n",
       " ('layer4.0.downsample.0.weight', 2097152, False),\n",
       " ('layer4.0.downsample.0.lora_A', 16384, True),\n",
       " ('layer4.0.downsample.0.lora_B', 32768, True),\n",
       " ('layer4.0.downsample.1.weight', 2048, True),\n",
       " ('layer4.0.downsample.1.bias', 2048, True),\n",
       " ('layer4.1.conv1.weight', 1048576, False),\n",
       " ('layer4.1.conv1.lora_A', 32768, True),\n",
       " ('layer4.1.conv1.lora_B', 8192, True),\n",
       " ('layer4.1.bn1.weight', 512, True),\n",
       " ('layer4.1.bn1.bias', 512, True),\n",
       " ('layer4.1.conv2.weight', 2359296, False),\n",
       " ('layer4.1.conv2.lora_A', 73728, True),\n",
       " ('layer4.1.conv2.lora_B', 73728, True),\n",
       " ('layer4.1.bn2.weight', 512, True),\n",
       " ('layer4.1.bn2.bias', 512, True),\n",
       " ('layer4.1.conv3.weight', 1048576, False),\n",
       " ('layer4.1.conv3.lora_A', 8192, True),\n",
       " ('layer4.1.conv3.lora_B', 32768, True),\n",
       " ('layer4.1.bn3.weight', 2048, True),\n",
       " ('layer4.1.bn3.bias', 2048, True),\n",
       " ('layer4.2.conv1.weight', 1048576, False),\n",
       " ('layer4.2.conv1.lora_A', 32768, True),\n",
       " ('layer4.2.conv1.lora_B', 8192, True),\n",
       " ('layer4.2.bn1.weight', 512, True),\n",
       " ('layer4.2.bn1.bias', 512, True),\n",
       " ('layer4.2.conv2.weight', 2359296, False),\n",
       " ('layer4.2.conv2.lora_A', 73728, True),\n",
       " ('layer4.2.conv2.lora_B', 73728, True),\n",
       " ('layer4.2.bn2.weight', 512, True),\n",
       " ('layer4.2.bn2.bias', 512, True),\n",
       " ('layer4.2.conv3.weight', 1048576, False),\n",
       " ('layer4.2.conv3.lora_A', 8192, True),\n",
       " ('layer4.2.conv3.lora_B', 32768, True),\n",
       " ('layer4.2.bn3.weight', 2048, True),\n",
       " ('layer4.2.bn3.bias', 2048, True),\n",
       " ('fc.weight', 2048000, True),\n",
       " ('fc.bias', 1000, True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
